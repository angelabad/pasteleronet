
<p>
<script type="text/javascript"><!--
google_ad_client = "pub-8023391092618680";
/* Noticia principal */
google_ad_slot = "2583678664";
google_ad_width = 468;
google_ad_height = 60;
//-->
</script>
<script type="text/javascript"
src="http://pagead2.googlesyndication.com/pagead/show_ads.js">
</script>
</p>

<p>
Artículo traducido de: <a
href="http://www.debian-administration.org/article/Speeding_up_dynamic_websites_via_an_nginx_proxy">Debian
Administration</a>
</p>

<p>
La mayoría de nosotros estamos familiarizados con el uso de Apache
para albergar sitios web. Puede que no sea el servidor web más rápido,
pero es extremadamente popular, extremadamente flexible y una buena
elección para la mayoría de la gente. Aún así hay ocasiones en las que
puede ponernos en un apuro, y configurar un proxy delante nos puede
venir muy bien.
</p>

<p>
<a href="http://wiki.nginx.org/">nginx</a> es un servidor HTTP muy
ligero, rápido y eficiente y muy bien pensado para trabajar como proxy
inverso, y no solo para HTTP, sino que también soporta SMTP.
</p>

<!--break-->

<p>
Recientemente he actualizado <a
href="http://www.debian-multimedia.org">este sitio</a> - ya que estaba
sufriendo mucha carga - esta pequeña introducción son los cambios que
hice.
</p>

<p>
Este sitio, como la mayoría, está construido a partir de una mezcla de
recursos estáticos y contenido generado dinámicamente. En nuestro caso
el contenido dinámico es generado por <a
href="http://www.debian-administration.org/Code/">una colección de
scripts CGI Perl</a>. Esta breve explicación prar usar nginx se podría
aplicar a cualquier sitio con una mezcla de recursos estáticos y
dinámicos, de la misma forma sería igual de aplicable para un sitio
Ruby on Rails o basado en PHP.
</p>

<p>
Durante los dos últimos años he venido observando que Apache 2.x
ofrece un buen desempeño en un día normal, pero en cuanto sube la
carga ya no se comporta todo lo bien que cabría esperar. A parte de
añadir mas memória a este servidor también me planteé cambiarle la
configuración para apliarle el número de conexiones y hits que puede
soportar.
</p>

<p>
Mi plan era:
</p>

<ul>
  <li>
    Tocar la configuración de Apache lo mínimo posible.
  </li>
  <ul>
    <li>
      En caso de que algo fallase quería tener la seguridad de poder
      revertir los cambios facilmente.
    </li>
  </ul>
  <li>
    Dejar que Apache siga sirviendo todo el contenido dinámico como lo
    estaba haciendo hasta ahora.
  </li>
  <li>
    Colocar un servidor HTTP dedicado más pequeño, rápido y simple
    para servir los contenidos estáticos.
  </li>
  <ul>
    <li>
      Con la expectativa de que esto dejase a Apache más liberado para
      servir el contenido dinámico.
    </li>
  </ul>
</ul>

<p>
Hay varias formas de llevar este plan a cabo, pero las dos más obvias
eran:
</p>

<h3>Cambiar los recursos de sitio</h3>

<p>
Podríamos dividir el manejo de los recursos estáticos moviendolos. Por
ejemplo en ver de servir y hospedar
http://www.debian-administration.org/images/logo.png podríamos moverlo
a un dominio diferente, como por ejemplo
http://images.debian-administration.org/logo.png.
</p>

<p>
Podríamos tener creado otro subdominio "static." para albergar otros
contenidos, como los archivos CSS o Javascript.
</p>

<p>
Esto nos permitiría configurar un segundo servidor web para manejar el
contenido estático de forma muy fácil (tal vez en un servidor
diferente, pero muy probablemente en la misma). El inconveniente de
esta solución es que requiere que actualicemos el código de nuestro
sitio, plantillas y posiblemente otros ficheros.
</p>

<h3>Introduciendo un Proxy</h3>

<p>
Para evitar tener que andar moviendo los recursos y el trabajo extra
que esto supone, la solución más simple sería colocar un proxy delante
de Apache. Este examinará las peticiones entrantes HTTP y las enviará,
ya sea a:
</p>

<ul>
  <li>
    Apache si es una petición para /cgi-bin/
  </li>
  <li>
    Otro servidor dedicado para todo el contenido estático
    (p.e. *.gif, *.png)
  </li>
</ul>

<p>
La decisión de por que usar nginx fué muy simple, existen varios
proxies en el mercado bien considerados. Pero nginx era el mejor
candidato por que se centra en ser a la vez un servidor HTTP y un
proxy muy rápido.
</p>

<p>
Al trabajar como proxy y servidor HTTP, reduce la cantidad de software
que tenemos que utilizar. Si hubieramos dedicado un proxy dedicado,
habriamos tenido que tener tres servidores funcionando:
</p>

<ul>
  <li>
    El proxy para recibir las peticiones.
  </li>
  <ul>
    <li>
      Apache2 para servir el contenido dinámico.
    </li>
    <li>
      Un servidor HTTP para el contenido estático.
    </li>
  </ul>
</ul>

<p>
Con nginx en escena tenemos una configurución muy simple con sólo dos
servidores corriendo:
</p>

<ul>
  <li>
    nginx acepta las peticiones e inmediatamente sirve el contenido estático.
  </li>
  <ul>
    <li>
      Apache recive las peticiones dinámicas que nginx no atendió.
    </li>
  </ul>
</ul>

<h3>Instalar nginx</h3>

<p>
La instalación de nginx fué tan simple como esperabamos en servidor
Debian GNU/Linux:
</p>

<pre>
# aptitude install nginx
</pre>

<p>
Una vez instalado, todos los ficheros de configuración se encuentran
bajo el directorio <em>/etc/nginx</em>. Como en el caso de los
paquetes de apache2 en Debian se colocan lass configuraciones de los
sitios habilitados bajo un directorio <em>sites-enables</em>.

<p>
Bien, tampoco se pare mucho con los ficheros de configuración de
<em>nginx</em> - el más importante es <em>/etc/nginx/nginx.conf</em> y
está muy bien explicado y se lee muy fácil. El único cambio que
tenemos que hacer es borrar el fichero
<em>/etc/nginx/sites-enabled/default</em>.
</p>

<h3>Configurar nginx y apache2</h3>

<p>
Configurar <em>nginx</em> es muy simple, y nuestra configuración actual
consistirá de dos partes:
</p>

<ul>
  <li>
    Configurar nginx para que escuche en el puerto 80, y redirija
    ciertas peticiones a Apache.
  </li>
  <li>
    Cambiar la configuración en Apache para que no siga escuchando
    bajo *:80, cambiandolo por el puerto que vayamos a utilizar.
  </li>
</ul>

<p>
Nuestro sitio se compone de dos hosts virtuales, nuestra <a
href="http://www.debian-administration.org">página principal</a> y
nuestro <a
href="http://planet.debian-administration.org">planet</a>. Este último
es con mucho el más simple, ya que no tiene contenido dinámico,
unicamente ficheros estáticos.
</p>

<p>
La configuración del sitio estático consiste en crear un fichero de
configuración para ello en
<em>/etc/nginx/sites-available/planet.conf</em> con el siguiente
contenido:
</p>

<pre>
#
# planet-debian-administration.org is 100% static, so nginx can
# serve it all directly.
#
server {
       listen :80;

       server_name  planet.debian-administration.org;

       access_log   /home/www/planet.debian-administration.org/logs/access.log;

       root         /home/www/planet.debian-administration.org/htdocs/;
}
</pre>

<p>
Esto es suficiente para que nginx sirva el host virtual
<em>planet.debian-administration.org</em> desde el directorio
<em>/home/www/planet.debian-administration.org/htdocs</em> - y logee
las peticiones entrantes en el fichero adecuado.
</p>

<p>
El manejo dinámico de nuestro sitio principal es un poco mas
complicado. El contenido del fichero de configuración
<em>/etc/nginx/sites-enabled/d-a.conf</em> sería algo así:
</p>

<pre>
#
#  This configuration file handles our main site - it attempts to
# serve content directly when it is static, and otherwise pass to
# an instance of Apache running upon 127.0.0.1:8080.
#
server {
       listen :80;

       server_name  www.debian-administration.org debian-administration.org;
       access_log  /var/log/nginx/d-a.proxied.log;

       #
       # Serve directly:  /images/ + /css/ + /js/
       #
       location ^~ /(images|css|js) {
               root   /home/www/www.debian-administration.org/htdocs/;
               access_log  /var/log/nginx/d-a.direct.log ;
       }

       #
       # Serve directly: *.js, *.css, *.rdf,, *.xml, *.ico, & etc
       #
       location ~* \.(js|css|rdf|xml|ico|txt|gif|jpg|png|jpeg)$ {
               root   /home/www/www.debian-administration.org/htdocs/;
               access_log  /var/log/nginx/d-a.direct.log ;
       }

       #
       # Proxy all remaining content to Apache
       #
       location / {

           proxy_pass         http://127.0.0.1:8080/;
           proxy_redirect     off;

           proxy_set_header   Host             $host;
           proxy_set_header   X-Real-IP        $remote_addr;
           proxy_set_header   X-Forwarded-For  $proxy_add_x_forwarded_for;

           client_max_body_size       10m;
           client_body_buffer_size    128k;

           proxy_connect_timeout      90;
           proxy_send_timeout         90;
           proxy_read_timeout         90;

           proxy_buffer_size          4k;
           proxy_buffers              4 32k;
           proxy_busy_buffers_size    64k;
           proxy_temp_file_write_size 64k;
       }
}
</pre>

<p>
Este fichero de configuración tiene varios puntos interesantes, pero
para los detalles completos necesitará consultar la <a
href="http://wiki.nginx.org/">documentación de nginx</a>. Obviamente
las secciones de más interes son las reglas que determinan que
contenido es gestionado directamente por nginx.
</p>

<p>
Verá que tenemos dos reglas diferentes:
</p>

<ul>
  <li>
    Una regla que dice que todo lo que esté por debajo de
    <em>/images/</em>, <em>css</em> o <em>js</em> debería ser
    gestionado directamente.
  </li>
  <li>
    Otra regla que dice que independientemente de la ubicación los
    ficheros <em>*.js</em>, <em>*.css</em>, <em>*.rdf</em>,
    <em>*.xml</em>, etc... siempre serán gestionados directamente.
  </li>
</ul>

<p>
Estas reglas podrían parecer redundantes pero es mejor ser explicito
acerca de nuestras intenciones. El resto del fichero contiene
configuraciones para el reenvio de todas las demás peticiones a la
instancia local de Apache - aquí no hicé cambios en la configuración
de ejemplo.
</p>

<p>
El otro punto a tener en cuenta es que logeo las peticiones entrantes
en dos ficheros, dependiendo de si son reenviadas a nuestra instancia
de Apache o gestionadas directamente. Esto no es obligatorio pero da
una idea de que peticiones van a cada servidor.
</p>

<p>
Con estos dos ficheros de configuración ya tenemos casi todo, sólo
tenemos que asegurarnos de que Apache nunca más bloqueará el puerto 80
para sí. Esto lo hacemos modificando el fichero
<em>/etc/apache2/ports.conf</em> parar que quede de la siguiente
manera:
</p>

<pre>
NameVirtualHost *:8080
Listen 8080

&lt;IfModule mod_ssl.c&gt;
    # SSL name based virtual hosts are not yet supported, therefore no
    # NameVirtualHost statement here
    Listen 443
&lt;/IfModule&gt;
</pre>

<p>
Esto nos asegura que Apache escuchará en puerto 8080 y no en el
80. Ahora deberemos hacer cambios en las configuraciones de nuestros
virtual hosts. Por ejemplo <em>/etc/apache2/sites-enabled/debian-administration.org</em>:
</p>

<pre>
#  Debian Administration domain.
#
&lt;VirtualHost *:8080&gt;
        ServerAdmin webmaster@debian-administration.org
        ServerName www.debian-administration.org
        DirectoryIndex index.cgi index.html

        DocumentRoot /home/www/www.debian-administration.org/htdocs/
        ...
        ...
</pre>

<p>
Con estos cambios realizados ya podemos empezar a usar nuestro proxy:
</p>

<pre>
/etc/init.d/apache2 stop
/etc/init.d/nginx start
/etc/init.d/apache2 start
</pre>

<p>
(Paramos apache2 para que el puerto 80 quede libre, entonces
arrancamos nginx que usará ese puerto, y finalmente reiniciamos
apache2 que a partir de ahora estará disponible en el puerto 8080 a
través del cual nginx puede hablar con él.)
</p>

<p>
<b>Nota</b>: En este ejemplo apache está escuchando en el puerto 8080
en todas las IPs en vez de solo en 127.0.0.1:8080 - Estó lo cambié
después.
</p>

<h3>Problemas experimentados</h3>

<p>
A la hora de hacer el despliegue se plantean dos problemas con los que
antes no se había contado:
</p>

<ul>
  <li>
    Falta de soporte IPv6.
  </li>
  <li>
    Se logean direcciones IP incorrectas
  </li>
</ul>

<p>
Desafortunadamente la versión de nginx disponible en la versión Lenny
de Debian no tiene soporte IPv6 - esto es una verdadera lástima ya que
llevamos corriendo sobre IPv6 ya bastante tiempo (Sobre el 3% de
nuestros visitantes usan IPv6 nativo, incluyendome a mi mismo, y no me
gustaría perderlos.)
</p>

<p>
La solución al problema con IPv6 fue hacer un backport del paquete
disponible en la distribución Debian inestable (un proceso dolorosa). 
Después de hecho esto el archivo de configuración de nginx debería
actualizarse de la siguiente manera:
</p>

<pre>
# Listen on both IPv6 & IPv4.
listen [::]:80;
</pre>

<p>
El segundo problema estaba relacionado con como Apache recibía todas
las conexiones desde el mundo exterior a través de nuestro servidor
local <em>nginx</em>. Esto significaba que Apache identificaba cada
petición entrante la hacía la IP 127.0.0.1.
</p>

<p>
Afortunadamente había una solución muy simple a este problema, el
módulo para Apache 2.x <a
href="http://packages.debian.org/libapache2-mod-rpaf">libapache2-mod-rpaf</a>
permite hacer visible la IP del exterior y poder logearla.
</p>

<p>
El módulo RPAF coge la dirección IP de donde se inició la conexión
original, y que nginx coloca en una cabecera <em>X-Forwarded-For</em>,
además se asegura de que esta IP está disponible para nuestros scripts
dinámicos y los logs de apache.
</p>

<p>
Aplicar esta solución fué tan simple como:
</p>

<pre>
aptitude install libapache2-mod-rpaf
a2enmod rpaf
/etc/init.d/apache2 force-reload
</pre>

<p>
Después de hacer esto nuestras conexiones entrantes eran logeadas
correctamente y nuestro código veia la IP real de cada conexión en
lugar de la de loopback del servidor proxy.
</p>

<h3>Cambios potenciales</h3>

<p>
Como habrás podido ver en los ficheros de configuración todas las
peticiones entrantes al puerto 80 serán gestionadas directamente o
reenviadas - pero no he hecho cambios en la gestión del puerto 443, o
las peticiones SSL.
</p>

<p>
Hemos ofrecido SSL durante un largo periodo de tiempo pero pocos
visitantes los utilizaban, asi que opté por dejar esto como está.
</p>

<p>
Si la situación cambia entonces se actualizará <em>nginx</em> para que
haga de proxy para las peticiones SSL también - tiene soporte para
ello, como indica la documentación.
</p>

<p>
Todavía es demasiado pronto para decir si esta solución ha
incrementado nuestra escalabilidad, pero soy muy optimista. El uso de
recursos ha caido y la combinación de <em>nginx</em> y <em>apache</em>
es muy buena y no demasiado complicada.
</p>
